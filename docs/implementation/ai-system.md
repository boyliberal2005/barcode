# AI SYSTEM DEEP DIVE

**Status**: 0% â†’ Target 80%
**Timeline**: 22-28 weeks (Phases 2A-2E)
**Last Updated**: 2025-11-06

---

## ğŸ¯ OVERVIEW

The AI system is **70% of what makes this system "smart"**. Without AI, this is just a normal POS.

### 7 Major AI Components

| Component | Business Impact | Complexity | Priority | Weeks |
|-----------|----------------|------------|----------|-------|
| **1. FaceID Recognition** | Critical â­â­â­â­â­ | High | P0 | 5 |
| **2. Voice AI (STT/NLU/TTS)** | Critical â­â­â­â­â­ | High | P0 | 8 |
| **3. PromptOps** | High â­â­â­â­ | Medium | P1 | 2 |
| **4. Demand Forecasting** | High â­â­â­â­ | Medium | P1 | 4 |
| **5. Upsell/Recommend** | Medium â­â­â­ | Medium | P2 | 3 |
| **6. Workforce Scheduling** | Medium â­â­â­ | Medium | P2 | 4 |
| **7. Anomaly Detection** | Medium â­â­â­ | Low | P2 | 2 |

**Total Estimated Effort**: 22-28 weeks

---

## ğŸ”´ 1. FACEID RECOGNITION (Phase 2A - 5 weeks) â­ HIGHEST PRIORITY

### Why This Matters

**Business Impact**: THE core differentiator
- **Customer Experience**: "Xin chÃ o anh Nam! Anh uá»‘ng Latte nhÆ° má»i khi khÃ´ng?" (personalized greeting)
- **Loyalty Integration**: Auto-lookup points, tier, purchase history
- **Upsell**: Recommend based on preferences
- **Opt-in Rate**: Target > 60% of customers

**Without FaceID**: This is just a normal POS with QR code loyalty. Not "smart".

---

### Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Camera    â”‚
â”‚  (1080p)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Image (RGB)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YuNet Face Detector (ONNX)                 â”‚
â”‚  - Bounding box (x, y, w, h)                â”‚
â”‚  - 5 landmarks (eyes, nose, mouth corners)  â”‚
â”‚  - Confidence score                         â”‚
â”‚  - Target: < 100ms p95                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Face ROI + Landmarks
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5-Point Alignment                          â”‚
â”‚  - Affine transform to canonical pose       â”‚
â”‚  - Crop to 112x112                          â”‚
â”‚  - Normalize pixels [0, 1]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Aligned Face
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embedder (MobileFaceNet or ArcFace)        â”‚
â”‚  - 128-dim embedding vector                 â”‚
â”‚  - L2 normalization                         â”‚
â”‚  - Target: < 100ms p95                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Embedding (128-dim)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  pgvector Similarity Search                 â”‚
â”‚  - Cosine similarity (IVFFlat or HNSW)      â”‚
â”‚  - Threshold: 0.75-0.80 (profile-dependent) â”‚
â”‚  - Target: < 100ms p95                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€> MATCH â”€â”€> customer_id
       â”‚             â”œâ”€> Loyalty Account
       â”‚             â”œâ”€> Purchase History
       â”‚             â”œâ”€> Personalized Recommendations
       â”‚             â””â”€> TTS Greeting
       â”‚
       â””â”€> NO MATCH â”€â”€> Prompt Opt-in
                        â””â”€> Register Face
```

**Total Latency Target**: < 300ms p95

---

### 3 Performance Profiles

| Profile | Model | Threshold | Liveness | Use Case |
|---------|-------|-----------|----------|----------|
| **Lite** | MobileFaceNet int8 | 0.75 | âŒ No | Fast food, high throughput |
| **Balanced** â­ | ArcFace R50 int8 | 0.78 | âœ… Yes | Recommended for cafe |
| **Max** | ArcFace R100 fp16 | 0.80 | âœ… Yes | High security, VIP |

**Recommendation**: Start with **Balanced** profile.

---

### Database Schema

```sql
CREATE EXTENSION IF NOT EXISTS vector;

-- Face embeddings table
CREATE TABLE face_embeddings (
  customer_id uuid PRIMARY KEY REFERENCES customers(id),
  embedding vector(128) NOT NULL,
  enc_method text DEFAULT 'aes-256-gcm',
  profile text CHECK (profile IN ('lite', 'balanced', 'max')),
  created_at timestamptz DEFAULT now(),
  updated_at timestamptz DEFAULT now()
);

-- IVFFlat index for fast search (good for < 100k faces)
CREATE INDEX idx_face_embeddings_vec
  ON face_embeddings USING ivfflat (embedding vector_cosine_ops)
  WITH (lists = 100);

-- For scale > 100k faces, use HNSW:
-- CREATE INDEX idx_face_embeddings_hnsw
--   ON face_embeddings USING hnsw (embedding vector_cosine_ops)
--   WITH (m = 16, ef_construction = 64);

-- Consent tracking (GDPR)
CREATE TABLE customer_consents (
  customer_id uuid REFERENCES customers(id),
  consent_type text CHECK (consent_type IN ('faceid', 'sms', 'email', 'zalo')),
  granted boolean NOT NULL,
  granted_at timestamptz,
  revoked_at timestamptz,
  PRIMARY KEY (customer_id, consent_type)
);

-- Audit log
CREATE TABLE face_access_log (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  customer_id uuid REFERENCES customers(id),
  action text CHECK (action IN ('recognize', 'register', 'delete')),
  confidence numeric(5, 4),
  ip_address inet,
  user_agent text,
  created_at timestamptz DEFAULT now()
);
```

---

### API Endpoints

#### 1. POST /face/recognize

**Request**:
```typescript
interface RecognizeRequest {
  image: string; // base64-encoded RGB image
  profile?: 'lite' | 'balanced' | 'max'; // default: balanced
  includeRecommendations?: boolean; // default: true
}
```

**Response**:
```typescript
interface RecognizeResponse {
  matched: boolean;
  customerId?: string;
  confidence?: number; // 0.0-1.0
  profile: string;
  latency: {
    detection: number; // ms
    embedding: number; // ms
    search: number; // ms
    total: number; // ms
  };
  loyalty?: {
    points: number;
    tier: 'bronze' | 'silver' | 'gold' | 'platinum';
    nextTierPoints: number;
  };
  recommendations?: MenuItem[];
  greeting?: string; // for TTS: "Xin chÃ o anh Nam!"
}
```

**Example**:
```json
{
  "matched": true,
  "customerId": "uuid-123",
  "confidence": 0.87,
  "profile": "balanced",
  "latency": {
    "detection": 85,
    "embedding": 92,
    "search": 78,
    "total": 255
  },
  "loyalty": {
    "points": 1250,
    "tier": "silver",
    "nextTierPoints": 250
  },
  "recommendations": [
    { "id": "item-1", "name": "Caramel Latte", "price": 55000, "reason": "Your favorite" },
    { "id": "item-2", "name": "Cheesecake", "price": 45000, "reason": "Pairs well" }
  ],
  "greeting": "Xin chÃ o anh Nam! Anh uá»‘ng Latte nhÆ° má»i khi khÃ´ng?"
}
```

---

#### 2. POST /customers/:id/face/register

**Request**:
```typescript
interface RegisterRequest {
  image: string; // base64
  profile?: 'lite' | 'balanced' | 'max';
  consent: boolean; // must be true
}
```

**Response**:
```typescript
interface RegisterResponse {
  success: boolean;
  customerId: string;
  message: string;
}
```

**Flow**:
1. Check consent granted (must be true)
2. Extract embedding from image
3. Encrypt embedding (AES-256-GCM)
4. Store in `face_embeddings` table
5. Log to `face_access_log`

---

#### 3. DELETE /customers/:id/face/delete

**GDPR Right to Be Forgotten**

**Request**: None (just customer ID in path)

**Response**:
```typescript
interface DeleteResponse {
  success: boolean;
  message: string;
  deletedAt: string;
}
```

**Flow**:
1. Delete from `face_embeddings`
2. Revoke consent in `customer_consents`
3. Log to `face_access_log`
4. Anonymize historical logs (GDPR requirement)

---

### Privacy & Security

#### 1. Opt-in Consent (GDPR)

**Consent Flow**:
```
Customer approaches kiosk
   â†“
FaceID: NO MATCH
   â†“
Display: "ÄÄƒng kÃ½ FaceID Ä‘á»ƒ Ä‘áº·t hÃ ng nhanh hÆ¡n?"
   [Äá»“ng Ã½]  [KhÃ´ng, cáº£m Æ¡n]
   â†“
If [Äá»“ng Ã½]:
   Show consent terms
   â†“
   Capture face image
   â†“
   Register embedding
   â†“
   Next visit: Auto-recognize!
```

**Consent Storage**:
```sql
INSERT INTO customer_consents (customer_id, consent_type, granted, granted_at)
VALUES ('uuid-123', 'faceid', true, now());
```

---

#### 2. Encryption (AES-256-GCM)

**Why**: Embeddings are biometric data (GDPR Article 9)

**Implementation**:
```typescript
import crypto from 'crypto';

export class FaceEmbeddingCrypto {
  private key: Buffer; // 32 bytes from env

  constructor() {
    this.key = Buffer.from(process.env.FACE_ENCRYPTION_KEY, 'hex');
  }

  encrypt(embedding: number[]): Buffer {
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv('aes-256-gcm', this.key, iv);

    const plaintext = Buffer.from(new Float32Array(embedding).buffer);
    const encrypted = Buffer.concat([cipher.update(plaintext), cipher.final()]);
    const authTag = cipher.getAuthTag();

    // Format: [IV (16 bytes)] [Auth Tag (16 bytes)] [Ciphertext]
    return Buffer.concat([iv, authTag, encrypted]);
  }

  decrypt(encrypted: Buffer): number[] {
    const iv = encrypted.slice(0, 16);
    const authTag = encrypted.slice(16, 32);
    const ciphertext = encrypted.slice(32);

    const decipher = crypto.createDecipheriv('aes-256-gcm', this.key, iv);
    decipher.setAuthTag(authTag);

    const plaintext = Buffer.concat([
      decipher.update(ciphertext),
      decipher.final(),
    ]);

    return Array.from(new Float32Array(plaintext.buffer));
  }
}
```

**Key Management**:
- Store in AWS Secrets Manager or similar
- Rotate every 90 days
- Use different keys per environment

---

#### 3. Audit Logging

**Log Every Access**:
```typescript
await this.prisma.faceAccessLog.create({
  data: {
    customerId,
    action: 'recognize',
    confidence: 0.87,
    ipAddress: req.ip,
    userAgent: req.headers['user-agent'],
  },
});
```

**Required for**:
- GDPR compliance (audit trail)
- Security investigations
- Fraud detection

---

### Performance Benchmarks

**Target SLO**:
| Metric | Target | Measurement |
|--------|--------|-------------|
| Face detection | < 100ms p95 | YuNet inference |
| Embedding extraction | < 100ms p95 | ArcFace inference |
| Vector search | < 100ms p95 | pgvector query |
| **Total latency** | < 300ms p95 | End-to-end |
| False Accept Rate | < 0.01% | Match when NOT same person |
| False Reject Rate | < 1% | NO match when IS same person |

**How to Measure**:
```typescript
const start = Date.now();

// Detection
const detectionStart = Date.now();
const faces = await this.detector.detect(image);
const detectionTime = Date.now() - detectionStart;

// Embedding
const embeddingStart = Date.now();
const embedding = await this.embedder.extract(faces[0]);
const embeddingTime = Date.now() - embeddingStart;

// Search
const searchStart = Date.now();
const match = await this.search(embedding);
const searchTime = Date.now() - searchStart;

const totalTime = Date.now() - start;

// Log to Prometheus
this.metrics.faceDetectionDuration.observe(detectionTime);
this.metrics.faceEmbeddingDuration.observe(embeddingTime);
this.metrics.faceSearchDuration.observe(searchTime);
this.metrics.faceRecognitionTotal.observe(totalTime);
```

---

### Testing Strategy

**1. Unit Tests**:
- Face detection accuracy (test images)
- Embedding consistency (same face â†’ same embedding)
- Encryption/decryption round-trip

**2. Integration Tests**:
- End-to-end flow: image â†’ customer_id
- Consent flow
- Delete flow

**3. Performance Tests**:
- Latency under load (100 RPS)
- Memory usage (model size)
- Concurrent requests (thread safety)

**4. Accuracy Tests**:
- False Accept Rate: 1000 different face pairs â†’ should NOT match
- False Reject Rate: 1000 same face pairs â†’ should match

---

### Deployment

**Infrastructure**:
- CPU: 4+ cores (ONNX Runtime uses all cores)
- RAM: 4GB+ (models + embeddings cache)
- GPU: Optional (TensorRT for 3x speedup)

**Docker Image**:
```dockerfile
FROM node:18-slim

# Install ONNX Runtime dependencies
RUN apt-get update && apt-get install -y \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Copy models
COPY models/ /app/models/

# Copy app
COPY . /app
WORKDIR /app

RUN pnpm install --prod
RUN pnpm build

CMD ["node", "dist/main.js"]
```

---

### Monitoring & Alerts

**Metrics to Track**:
- `face_recognition_latency_ms{percentile="p95"}` < 300
- `face_detection_latency_ms{percentile="p95"}` < 100
- `face_embedding_latency_ms{percentile="p95"}` < 100
- `face_search_latency_ms{percentile="p95"}` < 100
- `face_false_accept_rate` < 0.0001
- `face_false_reject_rate` < 0.01
- `face_optin_rate` > 0.60

**Alerts**:
- ğŸ”´ P0: Latency > 500ms p95 (affects customer experience)
- ğŸ”´ P0: False Accept Rate > 0.01% (security risk)
- ğŸŸ¡ P1: False Reject Rate > 2% (poor user experience)
- ğŸŸ¡ P1: Opt-in rate < 40% (low adoption)

---

### Rollout Plan

**Phase 1 (Week 11-12)**: Internal Testing
- Deploy to staging
- Test with team members (20 faces)
- Tune thresholds
- Fix bugs

**Phase 2 (Week 13)**: Pilot (1 Branch)
- Deploy to 1 branch
- Monitor for 1 week
- Target: 50 customers opt-in
- Measure SLOs

**Phase 3 (Week 14)**: Gradual Rollout
- Deploy to 5 branches
- Monitor for 1 week
- Target: 200 customers opt-in

**Phase 4 (Week 15)**: Full Rollout
- Deploy to all branches
- Marketing campaign: "Äáº·t hÃ ng nhanh vá»›i FaceID!"
- Target: 60% opt-in rate in 3 months

---

## ğŸ”µ 2. VOICE AI SYSTEM (Phase 2B - 8 weeks)

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VOICE AI PIPELINE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Microphone â†’ Audio Pipeline â†’ STT â†’ NLU â†’ TTS  â”‚
â”‚               (AEC/VAD/KWS)                      â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.1 Audio Pipeline

**WebRTC Processing**:
- **AEC** (Acoustic Echo Cancellation): Remove speaker feedback
- **NS** (Noise Suppression): Remove background noise
- **AGC** (Automatic Gain Control): Normalize volume
- **VAD** (Voice Activity Detection): Detect speech start/end

**Wake-Word Detection**:
- Porcupine (Picovoice): "Xin chÃ o" or custom wake word
- Always-listening mode
- Low CPU usage (< 5%)

**Implementation**:
```typescript
import Porcupine from '@picovoice/porcupine-node';

const porcupine = new Porcupine(
  accessKey,
  [Porcupine.KEYWORDS.HEY_GOOGLE], // or custom
  [0.5], // sensitivity
);

// In audio worklet
const keyword = porcupine.process(audioFrame);
if (keyword >= 0) {
  this.emit('wake-word-detected');
  // Start STT
}
```

---

### 2.2 STT (Speech-to-Text)

**Options**:

| Provider | Accuracy | Latency | Cost | Vietnamese Support |
|----------|----------|---------|------|-------------------|
| **Google Cloud STT** | Excellent | Low | $$$ | âœ… Excellent |
| **Azure Speech** | Excellent | Low | $$$ | âœ… Good |
| **FPT.AI** | Good | Medium | $$ | âœ… Excellent (local) |
| **Whisper (local)** | Good | High | Free | âœ… Good |

**Recommendation**: Google Cloud STT + Whisper fallback

**Implementation**:
```typescript
import speech from '@google-cloud/speech';

const client = new speech.SpeechClient();

const request = {
  config: {
    encoding: 'LINEAR16',
    sampleRateHertz: 16000,
    languageCode: 'vi-VN',
    model: 'latest_short',
    enableAutomaticPunctuation: true,
    enableWordTimeOffsets: true,
  },
  interimResults: true, // Partial transcripts
};

const recognizeStream = client
  .streamingRecognize(request)
  .on('data', (data) => {
    const result = data.results[0];
    const transcript = result.alternatives[0].transcript;

    if (result.isFinal) {
      this.emit('final-transcript', transcript);
    } else {
      this.emit('partial-transcript', transcript);
    }
  });

// Pipe audio
audioStream.pipe(recognizeStream);
```

**SLO**:
- First partial transcript: < 400ms
- Final transcript: < 2s (after speech ends)
- Accuracy: > 95% (Vietnamese cafe domain)

---

### 2.3 NLU (Natural Language Understanding)

**Task**: Parse order from speech

**Input**: "Cho mÃ¬nh má»™t ly Latte size lá»›n vÃ  má»™t cÃ¡i bÃ¡nh Cheesecake"

**Output**:
```json
{
  "items": [
    {
      "name": "Latte",
      "quantity": 1,
      "size": "L",
      "modifiers": []
    },
    {
      "name": "Cheesecake",
      "quantity": 1,
      "size": null,
      "modifiers": []
    }
  ],
  "confidence": 0.92,
  "clarification": null
}
```

**Model Options**:
1. **GPT-4** (OpenAI) - Best accuracy, high cost
2. **Grok-1** (xAI) - Fast, competitive
3. **Gemini Pro** (Google) - Good accuracy, low cost

**Implementation**:
```typescript
const prompt = `
Báº¡n lÃ  nhÃ¢n viÃªn order táº¡i quÃ¡n cafe. Parse order tá»« cÃ¢u nÃ³i cá»§a khÃ¡ch.

Menu:
${JSON.stringify(menuItems)}

CÃ¢u nÃ³i: "${transcript}"

Tráº£ vá» JSON:
{
  "items": [{ "name": string, "quantity": number, "size": "S|M|L", "modifiers": string[] }],
  "confidence": number,
  "clarification": string | null
}

Náº¿u khÃ´ng cháº¯c cháº¯n, set confidence < 0.7 vÃ  há»i láº¡i trong clarification.
`;

const response = await openai.chat.completions.create({
  model: 'gpt-4',
  messages: [{ role: 'system', content: prompt }],
  temperature: 0.1,
  max_tokens: 500,
});

const parsed = JSON.parse(response.choices[0].message.content);
```

**Guardrails**:
- Timeout: 5s max
- Retry: 2 attempts
- Fallback: Keyword matching (if AI fails)
- Cache: Redis (10-30 min TTL)

---

### 2.4 PromptOps (CRITICAL!)

**Why**: Control AI behavior without code changes

**Features**:
1. **Persona Presets** (vui váº», lá»‹ch sá»±, hÃ i hÆ°á»›c, chuyÃªn nghiá»‡p)
2. **Tone Sliders** (formal â†” casual)
3. **Context Packs** (menu, promos, loyalty tiers)
4. **A/B Testing** (test multiple prompt versions)
5. **Rollout** (gradual deployment 10% â†’ 50% â†’ 100%)
6. **Kill-Switch** (emergency disable AI)
7. **Guardrails** (content filtering, safety checks)

**Database Schema**:
```sql
CREATE TABLE ai_prompts (
  id uuid PRIMARY KEY,
  name text NOT NULL,
  version text NOT NULL,
  model text CHECK (model IN ('gpt-4', 'grok-1', 'gemini-pro')),
  persona text CHECK (persona IN ('friendly', 'formal', 'humorous', 'professional')),
  system_prompt text NOT NULL,
  context_packs jsonb, -- menu, promos, loyalty
  status text CHECK (status IN ('draft', 'testing', 'active', 'disabled')),
  rollout_percent int DEFAULT 0, -- 0-100%
  created_at timestamptz DEFAULT now()
);

CREATE TABLE ai_prompt_sessions (
  id uuid PRIMARY KEY,
  prompt_id uuid REFERENCES ai_prompts(id),
  customer_id uuid REFERENCES customers(id),
  transcript text,
  nlu_result jsonb,
  success boolean,
  latency_ms int,
  created_at timestamptz DEFAULT now()
);
```

**Example Personas**:
```typescript
const PERSONA_PRESETS = {
  friendly: {
    systemPrompt: 'Báº¡n lÃ  nhÃ¢n viÃªn order cafe thÃ¢n thiá»‡n, nhiá»‡t tÃ¬nh. LuÃ´n vui váº» vÃ  gáº§n gÅ©i.',
    tone: 'casual',
    examples: [
      { user: 'Cho mÃ¬nh 1 cafe', ai: 'Dáº¡ vÃ¢ng! Báº¡n uá»‘ng cafe gÃ¬ áº¡? Latte hay Americano? ğŸ˜Š' }
    ]
  },
  formal: {
    systemPrompt: 'Báº¡n lÃ  nhÃ¢n viÃªn order cafe lá»‹ch sá»±, chuyÃªn nghiá»‡p.',
    tone: 'formal',
    examples: [
      { user: 'Cho mÃ¬nh 1 cafe', ai: 'KÃ­nh chÃ o quÃ½ khÃ¡ch. QuÃ½ khÃ¡ch vui lÃ²ng cho biáº¿t loáº¡i cafe?' }
    ]
  }
};
```

**API Endpoints**:
- `GET /ai/prompts/presets` - List personas
- `POST /ai/prompts/deploy` - Deploy new version
- `GET /ai/prompts/sessions` - A/B test results
- `POST /ai/prompts/kill-switch` - Emergency disable

---

### 2.5 TTS (Text-to-Speech)

**Options**:
- **Edge TTS** (Microsoft): Free, good quality, Vietnamese
- **Google Cloud TTS**: Best quality, paid
- **FPT.AI**: Local, Vietnamese-optimized

**Implementation**:
```typescript
import edge from 'edge-tts';

const tts = new edge.Communicate({
  text: 'Xin chÃ o anh Nam! Anh uá»‘ng Latte nhÆ° má»i khi khÃ´ng?',
  voice: 'vi-VN-HoaiMyNeural', // Female voice
  rate: '+0%',
  pitch: '+0Hz',
});

const audioStream = await tts.stream();
// Send to WebSocket â†’ Frontend plays audio
```

**SLO**:
- TTS start latency: < 800ms
- Barge-in stop latency: < 200ms (when user speaks)

---

## ğŸŸ¢ 3. DEMAND FORECASTING (Phase 2C - 4 weeks)

[Detailed forecasting implementation...]

---

## ğŸŸ£ 4. UPSELL/RECOMMEND ENGINE (Phase 2D - 3 weeks)

[Detailed recommendation implementation...]

---

## ğŸŸ¤ 5. WORKFORCE SCHEDULING (Phase 2E - 4 weeks)

[Detailed workforce implementation...]

---

## ğŸŸ  6. ANOMALY DETECTION (Phase 2D - 2 weeks)

[Detailed anomaly detection implementation...]

---

## ğŸ“Š AI SYSTEM MONITORING

**Key Metrics**:
- `ai_stt_latency_ms{percentile="p95"}` < 400
- `ai_nlu_latency_ms{percentile="p95"}` < 5000
- `ai_tts_latency_ms{percentile="p95"}` < 800
- `ai_nlu_accuracy` > 0.95
- `ai_wake_word_false_positive_rate` < 0.01
- `face_recognition_latency_ms{percentile="p95"}` < 300

**Dashboard**: Grafana with AI metrics panel

---

**Last Updated**: 2025-11-06
**Next Review**: After each AI component completion
